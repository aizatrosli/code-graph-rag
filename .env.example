# Azure OpenAI Configuration (Recommended)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_ORCHESTRATOR_DEPLOYMENT=gpt-4o-mini
AZURE_CYPHER_DEPLOYMENT=gpt-35-turbo

# vLLM Configuration (For local high-performance inference)
# VLLM_ENDPOINT=http://localhost:8000/v1
# VLLM_ORCHESTRATOR_MODEL_ID=meta-llama/Llama-3.1-8B-Instruct
# VLLM_CYPHER_MODEL_ID=meta-llama/Llama-3.1-8B-Instruct
# VLLM_API_KEY=vllm

# DeepSeek Configuration
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_ENDPOINT=https://api.deepseek.com/v1
# DEEPSEEK_ORCHESTRATOR_MODEL_ID=deepseek-chat
# DEEPSEEK_CYPHER_MODEL_ID=deepseek-chat

# OpenAI Configuration
# OPENAI_API_KEY=your_openai_api_key_here

# Local model settings (Ollama)
# LOCAL_MODEL_ENDPOINT="http://localhost:11434/v1"
# LOCAL_ORCHESTRATOR_MODEL_ID="llama3"
# LOCAL_CYPHER_MODEL_ID="llama3"
# LOCAL_MODEL_API_KEY="ollama" # Ollama uses "ollama" as a placeholder

MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
LAB_PORT=3000
TARGET_REPO_PATH=.

# Shell Command Settings
SHELL_COMMAND_TIMEOUT=30
